{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4fb8d799d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gudhi as gd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import networkx as nx\n",
    "import scipy.sparse\n",
    "from nn_homology import nn_graph\n",
    "\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pts = 300   # number of points in the point clouds\n",
    "card  = 20    # max number of points in the diagrams\n",
    "hom   = 0     # homological dimension\n",
    "ml    = 5.   # max distance in Rips\n",
    "lr    = 1e-1  # learning rate\n",
    "lbda  = 0.3  # hyperparameter for topological loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_persistence(st, card, hom_dim):\n",
    "    st.persistence()\n",
    "    pairs = st.persistence_pairs()\n",
    "    dgm = np.zeros([card, 2], dtype=np.float32)\n",
    "    spl = np.zeros([card, 2*hom_dim + 3], dtype=np.int32)\n",
    "    mask = np.zeros([card], dtype=np.int32)\n",
    "    count = 0\n",
    "    for [splx0, splx1] in pairs:\n",
    "        # splx0 is negative simplex, splx1 is positive simplex\n",
    "        # these are arrays of ??indices?? that will be of length hom_dim+1\n",
    "        if len(splx0) - 1 == hom_dim and count < card and len(splx1) > 0:\n",
    "            dgm[count,0], dgm[count,1] = st.filtration(splx0), st.filtration(splx1)\n",
    "            # store the positive and negative simplices\n",
    "            spl[count,:hom_dim+1], spl[count,hom_dim+1:] = np.array(splx0), np.array(splx1)\n",
    "            # and track which points are relevant with mask\n",
    "            mask[count] = 1\n",
    "            count += 1\n",
    "    return [dgm, spl, mask]\n",
    "\n",
    "def compute_rips(card, hom_dim, D, max_length):\n",
    "    rc = gd.RipsComplex(distance_matrix=D, max_edge_length=max_length) # need to alter this to compute from distance matrix\n",
    "    st = rc.create_simplex_tree(max_dimension=hom_dim+1)\n",
    "    return compute_persistence(st, card, hom_dim)\n",
    "\n",
    "def compute_rips_grad(grad_dgm, dgm, spl, mask, c, h, params, adj, idx_vec, tol=1e-6):\n",
    "    grad_x = torch.zeros(params.shape) # need to alter this to respect x now being a list of tensors\n",
    "    for i in range(c[0]):\n",
    "        if mask[i] == 1:\n",
    "            val0, val1 = dgm[i,0], dgm[i,1]\n",
    "            splx0, splx1 = spl[i,:h[0]+1], spl[i,h[0]+1:]\n",
    "            # get rows in distance matrix according to each face of each simplex\n",
    "            D0, D1 = adj[splx0,:][:, splx0], adj[splx1,:][:, splx1]\n",
    "            \n",
    "            # find maximally distant simplices in filtration\n",
    "            [v0a, v0b] = list(splx0[np.argwhere(np.abs(D0-val0) <= tol)[0,:]])\n",
    "            [v1a, v1b] = list(splx1[np.argwhere(np.abs(D1-val1) <= tol)[0,:]])\n",
    "            \n",
    "            v0a = idx_vec[v0a]\n",
    "            v0b = idx_vec[v0b]\n",
    "            \n",
    "            v1a = idx_vec[v1a]\n",
    "            v1b = idx_vec[v1b]\n",
    "            \n",
    "            # v0a and v0b refer to the indices of the simplices in the lower dimension\n",
    "            # v1a and v1b refer to the indices of the simplices in the higher dimension\n",
    "            # need to alter these five lines.\n",
    "            if h[0] > 0:\n",
    "                grad_x[v0a] += grad_dgm[i,0] * (params[v0a] - params[v0b]) / val0\n",
    "                grad_x[v0b] += grad_dgm[i,0] * (params[v0b] - params[v0a]) / val0\n",
    "            grad_x[v1a] += grad_dgm[i,1] * (params[v1a] - params[v1b]) / val1\n",
    "            grad_x[v1b] += grad_dgm[i,1] * (params[v1b] - params[v1a]) / val1\n",
    "    return grad_x\n",
    "\n",
    "class Rips(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, params, adj, idx_vec, card, hom_dim, max_length):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        \n",
    "        dgm, spl, mask = compute_rips(card, hom_dim, adj, max_length)\n",
    "        ctx.dgm = dgm\n",
    "        ctx.spl = spl\n",
    "        ctx.card = card\n",
    "        ctx.hom_dim = hom_dim\n",
    "        ctx.adj = adj\n",
    "        ctx.idx_vec = idx_vec\n",
    "        ctx.params = params\n",
    "        return torch.tensor(dgm), torch.tensor(spl), torch.tensor(mask)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dgm_grad, spl_grad, mask_grad):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        dgm = ctx.dgm\n",
    "        spl = ctx.spl\n",
    "        c = ctx.card\n",
    "        h = ctx.hom_dim\n",
    "        params = ctx.params\n",
    "        adj = ctx.adj\n",
    "        idx_vec = ctx.idx_vec\n",
    "        grad_x = compute_rips_grad(dgm_grad.detach().numpy(), dgm, spl, mask, c, h, params, adj, idx_vec)\n",
    "        return None, None, grad_x, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3)\n",
    "        self.fc1 = nn.Linear(6912, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.param_info = [{'layer_type': 'Conv2d', 'kernel_size':(3,3), 'stride':1, 'padding': 0, 'name':'Conv1'},\n",
    "                            {'layer_type': 'Conv2d', 'kernel_size':(3,3), 'stride':1, 'padding':0, 'name':'Conv2'},\n",
    "                            {'layer_type':'Linear', 'name': 'Linear1'},\n",
    "                            {'layer_type':'Linear', 'name': 'Linear2'}]\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "    \n",
    "def sum_diag_loss(output, dgm, target, lbda=0.3):\n",
    "    diagloss = -torch.sum((dgm[:,1]-dgm[:,0])**2)\n",
    "    fn = F.nll_loss(output,target)\n",
    "    return fn + lbda*diagloss\n",
    "\n",
    "def flatten_params_torch(param_info, device):\n",
    "    param_vecs = []\n",
    "    for param in param_info:\n",
    "        if param['layer_type'] == 'Conv2d':\n",
    "            p = param['param']\n",
    "            param_vecs.append(p.reshape(p.shape[0],-1).flatten())\n",
    "        if param['layer_type'] == 'Linear':\n",
    "            p = param['param']\n",
    "            param_vecs.append(p.flatten())\n",
    "\n",
    "    # make the first element zero (could be anything given we're filtering below)\n",
    "    param_vecs = [torch.zeros(1).to(device)] + param_vecs\n",
    "    param_vec = torch.cat(param_vecs)\n",
    "\n",
    "    return param_vec\n",
    "    \n",
    "def train(model, G, device, train_loader, optimizer, epoch, log_interval=100):\n",
    "    rips = Rips.apply\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        G.update_adjacency(model)\n",
    "        \n",
    "        up = nn_graph.append_params(model.param_info, nn_graph.get_weights(model, tensors=True))\n",
    "        params = flatten_params_torch(up, device)\n",
    "        \n",
    "        output = model(data)\n",
    "        dgm, spl, msk = rips(params, G.get_adjacency(), G.graph_idx_vec, card, hom, ml)\n",
    "        loss = sum_diag_loss(output, dgm, target, lbda=lbda)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                datasets.MNIST('../../data', train=True, download=False,\n",
    "                transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=32, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=32, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Conv1\n",
      "Layer: Conv2\n",
      "Layer: Linear1\n",
      "Layer: Linear2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f4f9eaf0df0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNG = nn_graph.NNGraph()\n",
    "model = Net()\n",
    "NNG.parameter_graph(model, model.param_info, (1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.314465\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.229434\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.107913\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.314677\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.214002\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.139507\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.068457\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.149359\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2a9637354d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodeldev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNNG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodeldev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d7b3d6bd48e1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, G, device, train_loader, optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mdgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrips\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_adjacency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_idx_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_diag_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlbda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ab065a3482c7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, params, adj, idx_vec, card, hom_dim, max_length)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mdgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_rips\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhom_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdgm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ab065a3482c7>\u001b[0m in \u001b[0;36mcompute_rips\u001b[0;34m(card, hom_dim, D, max_length)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_rips\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhom_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRipsComplex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_edge_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to alter this to compute from distance matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simplex_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_dimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhom_dim\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_persistence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhom_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/schraterlab/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/schraterlab/anaconda3/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/schraterlab/anaconda3/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/schraterlab/anaconda3/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "modeldev = Net().to(device)\n",
    "optimizer = torch.optim.Adam(modeldev.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    train(modeldev, NNG, device, train_loader, optimizer, epoch)\n",
    "    test(modeldev, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
